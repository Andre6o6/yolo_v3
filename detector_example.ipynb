{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import time\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import cv2 \n",
    "from util import *\n",
    "import argparse\n",
    "import os \n",
    "import os.path as osp\n",
    "from darknet import Darknet\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "images = \"imgs\"\n",
    "batch_size = 1\n",
    "confidence = 0.5\n",
    "nms_thesh = 0.4\n",
    "\n",
    "det = \"det\"\n",
    "cfgfile = \"cfg/yolov3.cfg\"\n",
    "weightsfile = \"weights/yolov3.weights\"\n",
    "reso = 416\n",
    "\n",
    "start = 0\n",
    "CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 80    #For COCO\n",
    "classes = load_classes(\"data/coco.names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network.....\n",
      "Network successfully loaded\n"
     ]
    }
   ],
   "source": [
    "#Set up the neural network\n",
    "print(\"Loading network.....\")\n",
    "model = Darknet(cfgfile)\n",
    "model.load_weights(weightsfile)\n",
    "print(\"Network successfully loaded\")\n",
    "\n",
    "model.net_info[\"height\"] = reso\n",
    "inp_dim = int(model.net_info[\"height\"])\n",
    "assert inp_dim % 32 == 0 \n",
    "assert inp_dim > 32\n",
    "\n",
    "#If there's a GPU availible, put the model on GPU\n",
    "if CUDA:\n",
    "    model.cuda()\n",
    "\n",
    "#Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/andre6o6/aux/Projects/yolo_v3/imgs/black.png']\n"
     ]
    }
   ],
   "source": [
    "# Detection phase\n",
    "read_dir_time = time.time()    #checkpoint used to measure time\n",
    "# Load image directories\n",
    "try:\n",
    "    imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
    "except NotADirectoryError:\n",
    "    imlist = []\n",
    "    imlist.append(osp.join(osp.realpath('.'), images))\n",
    "except FileNotFoundError:\n",
    "    print (\"No file or directory with the name {}\".format(images))\n",
    "    \n",
    "if not os.path.exists(det):\n",
    "    os.makedirs(det)\n",
    "    \n",
    "read_dir_time = time.time() - read_dir_time\n",
    "print(imlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_batch_time = time.time()    \n",
    "# Load images\n",
    "#Numpy arrays for images in BGR\n",
    "loaded_ims = [cv2.imread(x) for x in imlist]\n",
    "\n",
    "#PyTorch Variables for images\n",
    "im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
    "\n",
    "#List containing dimensions of original images\n",
    "im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
    "im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
    "\n",
    "if CUDA:\n",
    "    im_dim_list = im_dim_list.cuda()\n",
    "    \n",
    "#Create the batches\n",
    "leftover = 0\n",
    "if (len(im_dim_list) % batch_size):\n",
    "    leftover = 1\n",
    "\n",
    "if batch_size != 1:\n",
    "    num_batches = len(imlist) // batch_size + leftover            \n",
    "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
    "                       len(im_batches))]))  for i in range(num_batches)]\n",
    "    \n",
    "load_batch_time = time.time() - load_batch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No detections were made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/andre6o6/aux/anaconda3/envs/nn/lib/python3.5/site-packages/torch/nn/functional.py:1749: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "output = None\n",
    "det_loop_time = time.time()\n",
    "#Loop through batches\n",
    "for i, batch in enumerate(im_batches):\n",
    "    start = time.time()\n",
    "    if CUDA:\n",
    "        batch = batch.cuda()\n",
    "\n",
    "    with torch.no_grad():   #autograd will not compute gradients in forward pass\n",
    "        prediction = model(Variable(batch), CUDA)\n",
    "        prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    if prediction is None:    #Objects not detected\n",
    "        continue\n",
    "\n",
    "    prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
    "\n",
    "    if output is None:                      #If we have't initialised output\n",
    "        output = prediction \n",
    "    else:\n",
    "        output = torch.cat((output,prediction))\n",
    "\n",
    "    for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
    "        im_id = i*batch_size + im_num\n",
    "        objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
    "        print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
    "        print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
    "        print(\"----------------------------------------------------------\")\n",
    "\n",
    "    if CUDA:\n",
    "        torch.cuda.synchronize()  #make sure CUDA returns control to CPU only after GPU work is done\n",
    "\n",
    "        \n",
    "det_loop_time = time.time() - det_loop_time\n",
    "\n",
    "if output is None:\n",
    "    print (\"No detections were made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_recast_time = time.time()\n",
    "\n",
    "#Transform the co-ordinates of the boxes to be measured with respect to boundaries of the area \n",
    "#on the padded image that contains the original image\n",
    "im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
    "\n",
    "scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)\n",
    "\n",
    "\n",
    "output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
    "output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
    "\n",
    "#Undo the rescaling\n",
    "output[:,1:5] /= scaling_factor\n",
    "\n",
    "#Clip any bboxes that have boundaries outside the image\n",
    "#TODO vectorize mb?\n",
    "for i in range(output.shape[0]):\n",
    "    output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
    "    output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
    "    \n",
    "output_recast_time = time.time() - output_recast_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = pkl.load(open(\"pallete\", \"rb\"))    #TODO get rid of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(x, results):\n",
    "    '''\n",
    "    Draws bounding box rectangle and rectangle with class name\n",
    "    '''\n",
    "    c1 = tuple(x[1:3].int())\n",
    "    c2 = tuple(x[3:5].int())\n",
    "    img = results[int(x[0])]\n",
    "    cls = int(x[-1])\n",
    "    color = random.choice(colors)\n",
    "    label = \"{0}\".format(classes[cls])\n",
    "    cv2.rectangle(img, c1, c2,color, 1)\n",
    "    t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "    c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
    "    cv2.rectangle(img, c1, c2,color, -1)\n",
    "    cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
    "    return img\n",
    "\n",
    "draw_time = time.time()\n",
    "\n",
    "list(map(lambda x: draw_bbox(x, loaded_ims), output))\n",
    "\n",
    "det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(det,x.split(\"/\")[-1]))\n",
    "\n",
    "list(map(cv2.imwrite, det_names, loaded_ims))\n",
    "draw_time = time.time() - draw_time\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "----------------------------------------------------------\n",
      "Task                     : Time Taken (in seconds)\n",
      "\n",
      "Reading addresses        : 0.001\n",
      "Loading batch            : 0.140\n",
      "Detection (1 images)     : 1.163\n",
      "Output Processing        : 0.002\n",
      "Drawing Boxes            : 0.410\n",
      "Average time_per_img     : 140.123\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#TODO keep dituration time, not checkpoints, because jupyter blocks \n",
    "print(\"SUMMARY\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
    "print()\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\",read_dir_time))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", load_batch_time))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", det_loop_time))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", output_recast_time))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", draw_time))\n",
    "print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end_time - start_time)/len(imlist)))\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
